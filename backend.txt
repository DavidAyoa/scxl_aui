import argparse
import os
import wave
import asyncio
import uvicorn
import sys
from pathlib import Path

from dotenv import load_dotenv
from loguru import logger
from typing import Any, Dict, Optional
from contextlib import asynccontextmanager

from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat_ai_small_webrtc_prebuilt.frontend import SmallWebRTCPrebuiltUI
from fastapi import BackgroundTasks, FastAPI, Request, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import RedirectResponse
from pipecat.frames.frames import (
    LLMMessagesAppendFrame,
)
from pipecat.frames.frames import (
    Frame,
    LLMFullResponseEndFrame,
    OutputAudioRawFrame,
    TTSSpeakFrame,
)
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineParams, PipelineTask
from pipecat.processors.aggregators.openai_llm_context import (
    OpenAILLMContext,
    OpenAILLMContextFrame,
)
from pipecat.processors.frame_processor import FrameDirection, FrameProcessor
from pipecat.processors.logger import FrameLogger
from pipecat.services.cartesia.tts import CartesiaTTSService
from pipecat.services.deepgram.stt import DeepgramSTTService
from pipecat.processors.aggregators.openai_llm_context import OpenAILLMContext
from pipecat.processors.frameworks.rtvi import (
    ActionResult,
    RTVIAction,
    RTVIActionArgument,
    RTVIConfig,
    RTVIObserver,
    RTVIProcessor,
    RTVIServerMessageFrame,
)
from pipecat.services.openai.llm import OpenAILLMService, OpenAIContextAggregatorPair
from pipecat.transports.base_transport import BaseTransport, TransportParams
from pipecat.transports.network.small_webrtc import SmallWebRTCTransport
from pipecat.transports.network.webrtc_connection import IceServer, SmallWebRTCConnection

load_dotenv(override=True)

# Configure logging format and level
logger.configure(
    handlers=[
        {
            'sink': sys.stdout,
            'level': os.getenv("LOG_LEVEL", "INFO"),
            'format': "<green>{time}</green> <level>{message}</level>",
        }
    ]
)

# Validate required environment variables at startup
def validate_environment():
    required_vars = [
        "DEEPGRAM_API_KEY",
        "OPENAI_API_KEY",
        "CARTESIA_API_KEY",
        "CARTESIA_VOICE_ID"
    ]
    
    missing_vars = [var for var in required_vars if not os.getenv(var)]
    if missing_vars:
        logger.error(f"Missing required environment variables: {', '.join(missing_vars)}")
        logger.info("Please add these variables to your .env file")
        sys.exit(1)
    
    logger.info("Environment variables validated successfully")

validate_environment()

app = FastAPI()

# Store connections by pc_id
pcs_map: Dict[str, SmallWebRTCConnection] = {}

ice_servers = [
    IceServer(
        urls="stun:stun.l.google.com:19302",
    )
]

# Mount the frontend at /
app.mount("/client", SmallWebRTCPrebuiltUI)

sounds = {}
sound_files = ["ding1.wav", "ding2.wav"]

script_dir = os.path.dirname(__file__)

# Load sound effects with error handling
for file in sound_files:
    try:
        full_path = os.path.join(script_dir, "sound_effects", file)
        filename = os.path.splitext(os.path.basename(full_path))[0]
        
        if not os.path.exists(full_path):
            logger.warning(f"Sound file not found: {full_path}")
            continue
            
        with wave.open(full_path) as audio_file:
            sounds[file] = OutputAudioRawFrame(
                audio_file.readframes(-1), audio_file.getframerate(), audio_file.getnchannels()
            )
        logger.info(f"Loaded sound effect: {file}")
    except Exception as e:
        logger.error(f"Error loading sound file {file}: {e}")


class OutboundSoundEffectWrapper(FrameProcessor):
    async def process_frame(self, frame: Frame, direction: FrameDirection):
        await super().process_frame(frame, direction)

        if isinstance(frame, LLMFullResponseEndFrame) and "ding1.wav" in sounds:
            await self.push_frame(sounds["ding1.wav"])
            # In case anything else downstream needs it
            await self.push_frame(frame, direction)
        else:
            await self.push_frame(frame, direction)


class InboundSoundEffectWrapper(FrameProcessor):
    async def process_frame(self, frame: Frame, direction: FrameDirection):
        await super().process_frame(frame, direction)

        if isinstance(frame, OpenAILLMContextFrame) and "ding2.wav" in sounds:
            await self.push_frame(sounds["ding2.wav"])
            # In case anything else downstream needs it
            await self.push_frame(frame, direction)
        else:
            await self.push_frame(frame, direction)

def create_action_llm_append_to_messages(context_aggregator: OpenAIContextAggregatorPair):
    async def action_llm_append_to_messages_handler(
        rtvi: RTVIProcessor, service: str, arguments: dict[str, any]
    ) -> ActionResult:
        run_immediately = arguments["run_immediately"] if "run_immediately" in arguments else True

        if run_immediately:
            await rtvi.interrupt_bot()

            # We just interrupted the bot so it should be fine to use the
            # context directly instead of through frame.
            if "messages" in arguments and arguments["messages"]:
                mess = arguments["messages"]
                frame = LLMMessagesAppendFrame(messages=arguments["messages"])
                await rtvi.push_frame(frame)

        if run_immediately:
            frame = context_aggregator.user().get_context_frame()
            await rtvi.push_frame(frame)

        return True

    action_llm_append_to_messages = RTVIAction(
        service="llm",
        action="append_to_messages",
        result="bool",
        arguments=[
            RTVIActionArgument(name="messages", type="array"),
            RTVIActionArgument(name="run_immediately", type="bool"),
        ],
        handler=action_llm_append_to_messages_handler,
    )
    return action_llm_append_to_messages


async def run_example(transport: BaseTransport, _: Optional[argparse.Namespace], handle_sigint: bool):
    try:
        logger.info(f"Starting bot")

        stt = DeepgramSTTService(api_key=os.getenv("DEEPGRAM_API_KEY"))
        llm = OpenAILLMService(api_key=os.getenv("OPENAI_API_KEY"))
        tts = CartesiaTTSService(
            api_key=os.getenv("CARTESIA_API_KEY"),
            voice_id=os.getenv("CARTESIA_VOICE_ID"),
        )

        messages = [
        {
            "role": "system",
            "content": "You are a helpful LLM in a WebRTC call. Your goal is to demonstrate your capabilities in a succinct way. Your output will be converted to audio. Respond to what the user said in a creative and helpful way.",
        },
        ]

        context = OpenAILLMContext(messages)
        context_aggregator = llm.create_context_aggregator(context)
        out_sound = OutboundSoundEffectWrapper()
        in_sound = InboundSoundEffectWrapper()
        fl = FrameLogger("LLM Out")
        fl2 = FrameLogger("Transcription In")

        # action_llm_append_to_messages = create_action_llm_append_to_messages(context_aggregator)
        # rtvi = RTVIProcessor(config=RTVIConfig(config=[]))
        # rtvi.register_action(action_llm_append_to_messages)

        rtvi = RTVIProcessor(config=RTVIConfig(config=[]))

        pipeline = Pipeline(
            [
                transport.input(),
                rtvi,
                stt,
                context_aggregator.user(),
                in_sound,
                fl2,
                llm,
                fl,
                tts,
                out_sound,
                transport.output(),
                context_aggregator.assistant(),
            ]
        )

        task = PipelineTask(
            pipeline,
            params=PipelineParams(
                enable_metrics=True,
                enable_usage_metrics=True,
            ),
            observers=[RTVIObserver(rtvi)],
        )

        @rtvi.event_handler("on_client_ready")
        async def on_client_ready(rtvi):
            logger.info("Pipecat client ready.")
            await rtvi.set_bot_ready()

            # This block is frontend UI specific
            # These messages are intended for small webrtc UI to only handle text
            # https://github.com/pipecat-ai/small-webrtc-prebuilt
            # messages = {
            #     "show_text_container": True,
            #     "show_debug_container": False,
            # }
            # rtvi_frame = RTVIServerMessageFrame(data=messages)
            # await task.queue_frames([rtvi_frame])

        @transport.event_handler("on_client_connected")
        async def on_client_connected(transport, client):
            logger.info(f"Client connected: {client}")
            # Kick off the conversation.
            await task.queue_frames([context_aggregator.user().get_context_frame()])
            if "ding1.wav" in sounds:
                # await transport.send_audio(sounds["ding1.wav"]) #webrtc
                await task.queue_frames([sounds["ding1.wav"]])

        @transport.event_handler("on_client_disconnected")
        async def on_client_disconnected(transport, client):
            logger.info(f"Client disconnected")

        # @transport.event_handler("on_client_closed")
        # async def on_client_closed(transport, client):
        #     logger.info(f"Client closed connection")
        #     await task.cancel()

        runner = PipelineRunner(handle_sigint=handle_sigint)
        await runner.run(task)
        
    except Exception as e:
        logger.error(f"Error in run_example: {e}")
        raise

@app.get("/", include_in_schema=False)
async def root_redirect():
    return RedirectResponse(url="/client/")

@app.post("/api/offer")
async def offer(request: dict, background_tasks: BackgroundTasks):
    try:
        pc_id = request.get("pc_id")

        if pc_id and pc_id in pcs_map:
            pipecat_connection = pcs_map[pc_id]
            logger.info(f"Reusing existing connection for pc_id: {pc_id}")
            await pipecat_connection.renegotiate(
                sdp=request["sdp"],
                type=request["type"],
                restart_pc=request.get("restart_pc", False),
            )
        else:
            pipecat_connection = SmallWebRTCConnection(ice_servers)
            await pipecat_connection.initialize(sdp=request["sdp"], type=request["type"])

            @pipecat_connection.event_handler("closed")
            async def handle_disconnected(webrtc_connection: SmallWebRTCConnection):
                logger.info(f"Discarding peer connection for pc_id: {webrtc_connection.pc_id}")
                pcs_map.pop(webrtc_connection.pc_id, None)

            transport = SmallWebRTCTransport(
                webrtc_connection=pipecat_connection,
                params=TransportParams(
                    audio_in_enabled=True,
                    audio_out_enabled=True,
                    vad_analyzer=SileroVADAnalyzer(),
                )
            )
            # Run example function with SmallWebRTC transport arguments.
            background_tasks.add_task(run_example, transport, None, False)

        answer = pipecat_connection.get_answer()
        # Updating the peer connection inside the map
        pcs_map[answer["pc_id"]] = pipecat_connection

        return answer
    except Exception as e:
        logger.error(f"Error handling offer: {e}")
        raise


@asynccontextmanager
async def lifespan(app: FastAPI):
    yield  # Run app
    try:
        coros = [pc.disconnect() for pc in pcs_map.values()]
        await asyncio.gather(*coros)
        pcs_map.clear()
        logger.info("Cleanup completed")
    except Exception as e:
        logger.error(f"Error during cleanup: {e}")
    
# Configure CORS to allow requests from any origin
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

if __name__ == "__main__":
    try:
        parser = argparse.ArgumentParser(description="Pipecat Bot Runner")
        parser.add_argument(
            "--host", default="localhost", help="Host for HTTP server (default: localhost)"
        )
        parser.add_argument(
            "--port", type=int, default=7860, help="Port for HTTP server (default: 7860)"
        )
        args = parser.parse_args()
        
        logger.info(f"Starting server on {args.host}:{args.port}")
        uvicorn.run(app, host=args.host, port=args.port)
        
    except KeyboardInterrupt:
        logger.info("Server interrupted by user")
    except Exception as e:
        logger.error(f"Server error: {e}")
        sys.exit(1)
